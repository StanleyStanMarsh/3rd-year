\documentclass[a4paper, final]{article}
%\usepackage{literat} % Нормальные шрифты
\usepackage[14pt]{extsizes} % для того чтобы задать нестандартный 14-ый размер шрифта
\usepackage{cmap}
\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage[left=25mm, top=20mm, right=20mm, bottom=20mm, footskip=10mm]{geometry}
\usepackage{ragged2e} %для растягивания по ширине
\usepackage{setspace} %для межстрочного интервала
\usepackage{moreverb} %для работы с листингами
\usepackage{indentfirst} % для абзацного отступа
\usepackage{moreverb} %для печати в листинге исходного кода программ
\renewcommand\verbatimtabsize{4\relax}
\renewcommand\listingoffset{0.2em} %отступ от номеров строк в листинге
\renewcommand{\arraystretch}{1.4} % изменяю высоту строки в таблице
\usepackage[font=small, singlelinecheck=false, justification=raggedleft, format=plain, labelsep=period]{caption} %для настройки заголовка таблицы
\usepackage{amssymb}
\usepackage{listings} %листинги
\usepackage{xcolor} % цвета
\usepackage{hyperref}% для гиперссылок
\usepackage{enumitem} %для перечислений
\usepackage{float}
\usepackage{graphicx}
\usepackage{multirow}

%\makeatletter 
%\@namedef{ver@float.sty}{3000/12/31}
%\makeatother

\usepackage{minted}
%\usemintedstyle{vs}
\definecolor{LightGray}{gray}{0.9}

\setlist[enumerate,itemize]{leftmargin=1.2cm} %отступ в перечислениях

\hypersetup{colorlinks,
	allcolors=[RGB]{010 090 200}} %красивые гиперссылки (не красные)
	
\captionsetup{justification=centering}


\begin{document}

		% НАЧАЛО ТИТУЛЬНОГО ЛИСТА
	\begin{center}
		\hfill \break
		\hfill \break
		\normalsize{МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ РОССИЙСКОЙ ФЕДЕРАЦИИ\\
			федеральное государственное автономное образовательное учреждение высшего образования «Санкт-Петербургский политехнический университет Петра Великого»\\[10pt]}
		\normalsize{Институт компьютерных наук и кибербезопасности}\\[10pt] 
		\normalsize{Высшая школа технологий искусственного интеллекта}\\[10pt] 
		\normalsize{Направление: 02.03.01 <<Математика и компьютерные науки>>}\\
		
		\hfill \break
		\hfill \break
		\hfill \break
		\hfill \break
		\large{Монады в Haskell}\\
		\large{\textit{Курсовая работа}}\\
		\hfill \break
		\hfill \break
		\hfill \break
		
		\hfill \break
		\hfill \break
	\end{center}
	
	\small{ 
		\begin{tabular}{lrrl}
			\!\!\!Студент, & \hspace{2cm} & & \\
			\!\!\!группы 5130201/20101 & \hspace{2cm} & \underline{\hspace{3cm}} &Астафьев И. Е. \\\\
			\!\!\!Преподаватель & \hspace{2cm} &  \underline{\hspace{3cm}} &  Моторин Д. Е.\\\\
			&&\hspace{5cm}
		\end{tabular}
		\begin{flushright}
			<<\underline{\hspace{1cm}}>>\underline{\hspace{2.5cm}} 2024г.
		\end{flushright}
	}
	
	\hfill \break
	\begin{center} \small{Санкт-Петербург, 2024} \end{center}
	\thispagestyle{empty} % выключаем отображение номера для этой страницы
	
	% КОНЕЦ ТИТУЛЬНОГО ЛИСТА
	\newpage
	
	\tableofcontents
	
	\newpage

\section*{Введение}
	\addcontentsline{toc}{section}{Введение}
		
	В данном отчете описаны результаты выполнения курсовой работы: монады в Haskell.
	
	\subsection*{Часть 1}

\textbf{Постановка задачи:}
	\begin{enumerate}

	\item Написать синтаксический анализатор (парсер), разбирающий строки, прочитанного файла .txt. Файл должен содержать значения и бинарные операции.
	\begin{itemize}
	
	\item Значения: строки битов
	\item Бинарные операции: AND(\&), OR(|), XOR(\(\oplus\))
	\item Пример строки в файле 01010 \& 0011. Вычислить проанализированное выражение результат вычисления на экран. Пользователь вводит название файла.
	\end{itemize}
	\end{enumerate}
	
\subsection*{Часть 2}
	
\textbf{Постановка задачи:}

\begin{enumerate}
    \item Прочитать текст из файла, указываемого пользователем. Синтаксически проанализировать текст согласно правилам: слова состоят только из букв; предложения состоят только из слов и разделены символами: !?;:. Разбить текст на предложения. Удалить все символы пунктуации и цифры из слов и предложений.
    \item Составить модель N-грамм. Использовать модель биграмм и триграмм. По списку предложений составить словарь. Ключами являются: одно слово, либо пара слов. Значениями в словаре является список всех уникальных возможных продолжений триграммы (т.е. список пар слов или одиночных слов). Словарь сохранить в файл .txt.

Пример текста и словаря на его основе:

Текст: [a b, c d e! b c d? e b c $\#$ a d. a f; f.] 

Словарь: ['a' : ['b', 'd', 'f', 'b c']; 'b' : ['c', 'c d', 'c a']; 'c' : ['d', 'a', 'd e', 'a d']; 'd' : ['e']; 'e' : ['b','b c']; f : []; 'a b' : ['c']; 'b c' : ['d', 'a']; 'c d' : ['e']; 'e b' : ['c']; 'c a' : ['d']; 'a d' : []; 'a f' : []; 'd e' : [].
    \item Реализовать взаимодействие с пользователем. Пользователь вводит одно слово или пару слов. Программа возвращает стоку случайной длины в диапазоне от 2 до 15 слов, если задаваемого пользователем слова нет в ключах словаря, выдавать соответствующее сообщение. Фраза составляется путем добавления случайного слова (или пары) из списка значений текущего слова-ключа (или пары-ключа), до тех пор, пока либо не будет сформировано предложение нужной длины, либо не будет достигнут ключ, у которого нет значений.
    \item Организовать диалог двух моделей N-грамм созданных на двух разных текстах. Тексты для второй модели выбрать самостоятельно. Пользователь задает начальное слово (или пару) и глубину М сообщений, которыми обмениваются модели. Ответ модели основывается на последнем слове из предложения оппонента (если последнее слово отсутствует в словаре, то предпоследнее и т.д. пока не будет найдено подходящее слово или не закончится предложение оппонента).
\end{enumerate}
 
Автор текстов: Максим Горький.
 
\newpage

	\section{Теоретические сведения}

\subsection{Синтаксический анализатор}

Синтаксический анализатор, или парсер, является ключевым компонентом любой системы обработки текста, языков программирования или данных. Его задача заключается в разборе входной последовательности символов (или токенов, если предварительно был выполнен лексический анализ) и проверке её соответствия заданной грамматике, а также в построении структуры данных, описывающей синтаксис входной строки.

\subsection{Основные этапы работы парсера}

Работа синтаксического анализатора включает следующие этапы:

\begin{enumerate}
    \item \textbf{Получение входных данных.} Парсер принимает последовательность символов или токенов на вход. Эти данные поступают либо напрямую из исходного текста, либо из лексического анализатора.
    \item \textbf{Проверка соответствия грамматике.} Парсер проверяет, соответствует ли входная строка правилам грамматики, заданным в виде контекстно-свободной грамматики (КС-грамматики) или другого формализма.
    \item \textbf{Построение выходной структуры.} Если строка соответствует грамматике, парсер формирует дерево разбора (дерево синтаксического анализа), абстрактное синтаксическое дерево (AST) или другую структуру данных, которая будет использоваться для последующей обработки.
\end{enumerate}

\paragraph{Типы синтаксических анализаторов}

Существуют различные типы синтаксических анализаторов, которые различаются по методам работы и применяемым алгоритмам:

\begin{itemize}
    \item \textbf{Восходящие парсеры (Bottom-up).} Эти парсеры строят дерево разбора, начиная с листьев (токенов) и продвигаясь вверх к корню. Примеры: алгоритмы LR, LALR и SLR.
    \item \textbf{Нисходящие парсеры (Top-down).} Такие парсеры начинают с корня дерева и рекурсивно обрабатывают правила грамматики, продвигаясь к листьям. Примером является рекурсивно-спускающийся парсер.
    \item \textbf{LL-парсеры.} Это подмножество нисходящих парсеров, которые обрабатывают грамматику слева направо (Left-to-right) и строят левую производную (Leftmost derivation).
    \item \textbf{Рекурсивно-спускающиеся парсеры.} Это парсеры, которые используют рекурсивные вызовы функций для обработки правил грамматики. Они просты в реализации и часто используются для разработки парсеров на языках программирования.
\end{itemize}

\subsection{Функторы}
Функторы — это абстракция, представляющая контейнеры, к элементам которых можно применять функции. Они принадлежат классу типов \texttt{Functor}, который определяет операцию \texttt{fmap}. Эта операция позволяет трансформировать содержимое контейнера, не изменяя его структуру. Например, с помощью \texttt{fmap} можно применить функцию ко всем элементам списка.

\subsection{Аппликативные функторы}
Аппликативные функторы расширяют возможности функторов, добавляя способ применения функций, заключённых в контексте, к значениям в том же контексте. Это реализуется через операции \texttt{<*>} и \texttt{pure} из класса типов \texttt{Applicative}. Операция \texttt{pure} помещает значение в контекст, а \texttt{<*>} применяет функцию из контекста к значениям, также находящимся в контексте. Аппликативные функторы полезны для работы с вычислениями, которые могут завершиться неудачей.

\subsection{Класс типов \texttt{Alternative}}
Класс типов \texttt{Alternative} используется для работы с контейнерами, которые могут содержать либо значения, либо быть пустыми. Основные операции:
\begin{itemize}
    \item \texttt{empty} — представляет пустой контейнер.
    \item \texttt{<|>} — предоставляет способ комбинирования двух контейнеров. Например, выбирает первый непустой контейнер.
\end{itemize}
\texttt{Alternative} часто используется в парсерах, где можно выбирать между различными вариантами анализа текста.

\subsection{Монады}
Монады — это обобщение аппликативных функторов, позволяющее связывать последовательные вычисления. Они определяются через операции \texttt{>>=} (bind) и \texttt{return}. Операция \texttt{return} помещает значение в контекст, а \texttt{>>=} позволяет передавать результат одного вычисления следующему. 

Монады обеспечивают удобство работы с вычислениями, которые могут быть последовательными, контекстуальными или содержать побочные эффекты. Они находят широкое применение в обработке ошибок, работе с вводом-выводом, парсерах и других задачах.

\subsection{N-граммы}

N-граммы — это последовательности из N элементов, получаемые из данных. В контексте обработки естественного языка (NLP) элементы обычно представляют собой слова или символы. Основной задачей N-грамм является моделирование и анализ последовательностей в тексте, что может быть полезно для различных задач, таких как предсказание следующего слова, анализ вероятности перехода от одного состояния к другому или классификация текста.

\textbf{Определение:}  
N-грамма — это последовательность из N элементов, где каждый элемент может быть как словом, так и символом, в зависимости от задачи. Если N = 1, то это называется \textit{унитарной граммой} или \textit{униграммой}, если N = 2 — \textit{биграммой}, N = 3 — \textit{триграммой} и так далее. Например:
\begin{itemize}
    \item Униграмма для текста "Я люблю читать": ["Я", "люблю", "читать"].
    \item Биграмма для того же текста: ["Я люблю", "люблю читать"].
    \item Триграмма: ["Я люблю читать"].
\end{itemize}

\textbf{Применение N-грамм в обработке естественного языка:}
\begin{itemize}
    \item \textit{Языковое моделирование:} N-граммные модели широко используются для оценки вероятности появления слова в определенном контексте. Например, биграммная модель будет оценивать вероятность появления слова на основе предыдущего слова.
    \item \textit{Предсказание текста:} Используя вероятности N-грамм, можно предсказать следующее слово в предложении. Если модель обучена на больших корпусах текста, она может точно угадывать следующее слово, основываясь на предыдущих N-1 словах.
    \item \textit{Классификация текста:} N-граммные признаки могут использоваться для представления текста в задачах классификации, таких как определение тональности текста или его тематической принадлежности.
\end{itemize}

В некоторых задачах моделирования языка или предсказания текста, для представления N-грамм удобно использовать словарь, где ключами являются N-граммы (представленные в виде строк), а значениями — последовательности элементов, которые могут следовать за данным контекстом.

Пример структуры такого словаря для биграмм может выглядеть следующим образом:

\[
\texttt{"a": ["b", "d", "b c"], "b c": ["f"], "f": []}
\]

Здесь:

\begin{itemize}
    \item Ключ "a" ассоциируется с массивом значений \texttt{["b", "d", "b c"]}, что означает, что после слова "a" могут следовать слова "b", "d" или "b c".
    \item Ключ "b c" ассоциируется с массивом \texttt{["f"]}, что означает, что после биграммы "b c" может следовать слово "f".
    \item Ключ "f" имеет пустой массив \texttt{[]}, что означает, что после слова "f" не ожидаются другие слова или элементы.
\end{itemize}

Этот словарь может использоваться в различных задачах обработки текста, таких как генерация текста или анализ вероятности появления слов. Основные преимущества этого подхода заключаются в том, что такой словарь позволяет:

\begin{itemize}
    \item \textbf{Хранить контексты} для каждой N-граммы, то есть, для каждого слова или последовательности слов хранить информацию о том, какие элементы могут следовать за ними.
    \item \textbf{Быстро искать возможные продолжения} для каждой N-граммы, что полезно при решении задач предсказания следующего слова или анализа текста.
    \item \textbf{Использовать для предсказания вероятности}, вычисляя вероятность появления следующего слова как частоту появления той или иной N-граммы в обучающем корпусе текста.
\end{itemize}

\newpage

\section{Часть 1. Парсер строк бинарных чисел и операций}



\subsection{Реализация программы}

Полный исходный код представлен в \hyperref[sec:binParser]{Приложение A. Парсер бинарных операций}.

\subsubsection*{Описание Parser}

\label{sec:parser}

В данном разделе представлен синтаксический анализатор (парсер), реализованный на языке Haskell. Его цель — поэтапный разбор текста с возможностью обработки ошибок и комбинирования простых парсеров в более сложные конструкции.

Парсер реализован как абстракция, представляющая собой функцию, которая принимает текст на вход и возвращает результат анализа в виде оставшегося текста и результата парсинга. В случае неудачного анализа результатом работы является специальное значение \texttt{Nothing}.

Основные возможности парсера обеспечиваются реализацией нескольких стандартных классов Haskell:

\begin{itemize}

\item Класс \texttt{Functor} позволяет применять функции к результату парсинга, не изменяя процесс самого анализа. Это достигается за счёт обёртки результата существующего парсера в новый парсер, который трансформирует результат с помощью переданной функции.

\item Класс \texttt{Applicative} позволяет комбинировать несколько парсеров, применяя функции с несколькими аргументами к их результатам. Этот механизм используется для построения последовательных цепочек парсеров. Например, можно объединить парсеры для разбора чисел и операторов в одном выражении.

\item Класс \texttt{Alternative} предоставляет средства для обработки альтернативных вариантов и восстановления после ошибок. С его помощью можно определять парсеры, которые пробуют несколько вариантов анализа и выбирают первый успешный результат.

\end{itemize}

Основной особенностью реализации является использование концепций функционального программирования, таких как иммутабельность данных и композиция функций, что делает код простым для комбинирования и тестирования. Такой подход позволяет строить мощные анализаторы для обработки текста с минимальными усилиями.

Разработанный парсер служит основой для построения высокоуровневых разборщиков, таких как парсер бинарных выражений, представленный в рамках данной работы.

\subsubsection*{Описание функций проверки и парсинга символов}

Для реализации базовых операций парсинга в коде используются следующие функции:

\begin{itemize}

\item\texttt{isBinaryChar}

   Данная функция проверяет, является ли символ допустимым двоичным символом (\texttt{'0'} или \texttt{'1'}). Она используется в парсерах, которые разбирают двоичные числа.  

\item\texttt{isOperation}

	Эта функция проверяет, относится ли символ к допустимым логическим операциям: \texttt{'\&'} (AND), \texttt{'|'} (OR) или \texttt{'\(\oplus\)'} (XOR). Она помогает распознать оператор в выражении.
	
\item\texttt{isSpace}

Проверяет, является ли символ пробелом (\texttt{' '}). Функция используется для обработки пробелов между элементами выражения.

\item\texttt{satisfy}

Универсальная функция-парсер, которая принимает предикат (функцию \texttt{Char -> Bool}) и создаёт парсер, возвращающий первый символ текста, удовлетворяющий предикату. Если текст пустой или первый символ не подходит под предикат, парсер возвращает \texttt{Nothing}.

Алгоритм работы:

\begin{enumerate}

\item Сначала извлекается первый символ строки с помощью функции \texttt{T.uncons}.
\item Если строка пуста (\texttt{Nothing}), парсер возвращает \texttt{Nothing}.
\item Если символ присутствует, проверяется выполнение предиката.
\begin{itemize}
\item При успешной проверке возвращается пара: оставшийся текст и символ.
\item При неудаче возвращается \texttt{Nothing}
\end{itemize}
\end{enumerate}
\end{itemize}

\subsubsection*{Простые парсеры}

В данном разделе описаны базовые парсеры, которые используются для распознавания и обработки текстовых данных, таких как двоичные числа, логические операции и пробелы. Эти парсеры являются ключевыми элементами для построения более сложных синтаксических анализаторов.

\begin{itemize}

\item \textbf{Парсер двоичных чисел.}  

Этот парсер считывает последовательность двоичных символов (\texttt{0} или \texttt{1}) из входного текста. Если первый символ строки является двоичным, он добавляется к результату. Парсер рекурсивно продолжает обработку оставшейся строки.  

На выходе:  
\begin{itemize}  
    \item Если парсинг завершился успешно, возвращается \texttt{Just (remainingText, parsedText)}, где \texttt{remainingText} — остаток строки после обработки, а \texttt{parsedText} — строка, состоящая из всех двоичных символов, считанных подряд.  
    \item Если первый символ не является двоичным или строка пустая, возвращается \texttt{Nothing}.  
\end{itemize} 

\item \textbf{Парсер операций.}  

Этот парсер использует функцию \texttt{satisfy}, чтобы найти первый символ, который соответствует одному из предопределённых операторов (\texttt{\&}, \texttt{|} или \texttt{?}). Функция \texttt{isOperation} проверяет, является ли символ одним из допустимых операторов. Если символ подходит, он возвращается как результат парсера.  

На выходе:  
\begin{itemize}  
    \item Если первый символ является одним из допустимых операторов, парсер возвращает \texttt{Just (remainingText, op)}, где \texttt{remainingText} — остаток строки после обработки, а \texttt{op} — сам символ оператора.  
    \item Если первый символ не является допустимым оператором, парсер возвращает \texttt{Nothing}.  
\end{itemize}

\item \textbf{Парсер одиночного пробела.}  

Этот парсер использует функцию \texttt{satisfy}, чтобы найти первый символ, который является пробелом. Функция \texttt{isSpace} проверяет, является ли символ пробелом. Если символ подходит, он возвращается как результат парсера.  

На выходе:  
\begin{itemize}  
    \item Если первый символ — пробел, парсер возвращает \texttt{Just (remainingText, ' ')}, где \texttt{remainingText} — остаток строки после обработки, а \texttt{' '} — символ пробела.  
    \item Если первый символ не является пробелом, парсер возвращает \texttt{Nothing}.  
\end{itemize} 

\item \textbf{Парсер последовательности пробелов.}  

Этот парсер использует комбинацию парсеров для обработки пробелов. Он рекурсивно использует \texttt{oneSpace} для поиска первого пробела, затем применяет себя (парсер \texttt{spaces}) для обработки оставшихся пробелов. В случае, если пробелы больше не найдены, используется \texttt{pure T.empty}, чтобы вернуть пустую строку.  

На выходе:  
\begin{itemize}  
    \item Если строка начинается с пробела, парсер возвращает строку из пробелов. Например, \texttt{Just (remainingText, " ")} в случае одного пробела или \texttt{Just (remainingText, "  ")} в случае двух пробелов.  
    \item Если строка не содержит пробелов или они закончились, парсер возвращает \texttt{Just (remainingText, "")}, то есть пустую строку.  
    \item Если первый символ не является пробелом, парсер возвращает \texttt{Nothing}.  
\end{itemize}  

\end{itemize}

\subsubsection*{Обработка логических операций и форматирование выражений}

Данный раздел описывает функции, которые выполняют вычисление логических операций над двоичными числами и форматируют выражения для удобного представления результата.

\begin{itemize}

\item \textbf{Функция для применения операций.}  
Функция \texttt{applyOperation} принимает символ, обозначающий логическую операцию (\texttt{\&}, \texttt{|}, \texttt{\^}), и возвращает соответствующую функцию, которая применяется к двум целым числам.  
\begin{itemize}
    \item Оператор \texttt{\&} интерпретируется как побитовое \textit{AND}.
    \item Оператор \texttt{|} интерпретируется как побитовое \textit{OR}.
    \item Оператор \texttt{\^} интерпретируется как побитовое \textit{XOR}.
\end{itemize}
Этот подход обеспечивает компактный и удобный способ выбора операции в зависимости от символа.

\item \textbf{Парсер для выражений с двоичными числами.}  

Этот парсер представляет собой комбинацию нескольких простых парсеров, который парсит строку, содержащую два бинарных числа и операцию между ними, игнорируя пробелы. Он использует парсер \texttt{spaces} для обработки возможных пробелов в начале, середине и конце выражения.  

Сначала парсится первое бинарное число с помощью парсера \texttt{binary}, который распознаёт последовательности символов \texttt{'0'} и \texttt{'1'}. Затем, между ними парсится операция (например, \texttt{\&}, \texttt{|} или \texttt{\^}) с помощью парсера \texttt{operation}. После этого снова пропускаются пробелы с помощью \texttt{spaces}. В завершение, парсится второе бинарное число с использованием того же парсера \texttt{binary}.  

Вся эта структура композиционно собрана с помощью оператора \texttt{<*>} из типа \texttt{Applicative}, что позволяет комбинировать несколько парсеров, обеспечивая удобную работу с каждым компонентом выражения. Полученные результаты передаются в функцию \texttt{formatExpression}, которая форматирует их в строку, включая результат вычисления операции. 

\item \textbf{Форматирование и вычисление выражения.}  
Функция \texttt{formatExpression} преобразует разобранные элементы выражения (два числа и операцию) в итоговый текст, включающий результат вычисления. Алгоритм:
\begin{itemize}
    \item Преобразует оба двоичных числа в целые числа.
    \item Применяет указанную операцию к этим числам с помощью функции \texttt{applyOperation}.
    \item Преобразует результат обратно в двоичный формат.
    \item Формирует строку вида \texttt{<число1> <операция> <число2> = <результат>}.
\end{itemize}
Пример: строка \texttt{"101 \& 010"} будет преобразована в \texttt{"101 \& 010 = 0"}.

\end{itemize}

Эти функции обеспечивают корректную обработку двоичных выражений, их вычисление и представление результата в удобочитаемой форме, что делает парсер удобным и эффективным инструментом для анализа логических выражений.


\newpage

\section{Часть 2. Генератор предложений с помощью N-грамм}

\subsection{Реализация программы}

Полный исходный код представлен в \hyperref[sec:phraseGen]{Приложение Б. Генератор предложений}.

\subsubsection*{Описание Parser}

Описание Parser идентично описанному в разделе \hyperref[sec:parser]{Описание Parser} в Части 1. 

\subsubsection*{Описание функций проверки и парсинга символов}

Для реализации базовых операций обработки текста в коде используются следующие функции:

\begin{itemize}

\item \texttt{isPunctuation}

    Эта функция проверяет, является ли символ знаком препинания. Она возвращает \texttt{True}, если символ входит в список \texttt{['.', '!', '?', ';', ':', '(', ')']}, и \texttt{False} в противном случае. Эта функция используется для определения наличия знаков препинания в строках, что может быть полезно при анализе текста или парсинге.

\item \texttt{joinWords}

    Функция принимает список строк \texttt{[Text]} и объединяет их в одну строку, вставляя между словами пробелы. Для этого используется функция \texttt{T.intercalate}, которая вставляет заданный разделитель (в данном случае пробел) между элементами списка и возвращает единую строку. Эта функция полезна для объединения слов или фраз в одно предложение или текст.
    
\item \texttt{isWordChar}

    Эта функция проверяет, является ли символ частью слова. Она возвращает \texttt{True}, если символ является буквой (проверяется с помощью функции \texttt{isLetter}) или если символ — это апостроф (\texttt{'}). Таким образом, эта функция может быть полезна для распознавания частей слов, например, для обработки таких случаев, как апострофы в английских словах (например, \texttt{"don't"} или \texttt{"it's"}).
    
\item \texttt{satisfy}

    Эта функция принимает предикат \texttt{pr} (функцию, проверяющую условие для символа) и возвращает парсер, который пытается применить этот предикат к первому символу строки. Если первый символ удовлетворяет предикату, парсер возвращает оставшуюся строку и сам символ, иначе возвращает \texttt{Nothing}. Функция полезна для парсинга отдельных символов, удовлетворяющих заданному условию, и может быть использована в различных парсерах для обработки символов, таких как цифры, пробелы или буквы.


\end{itemize}

\subsubsection*{Простые парсеры}

В данном разделе описаны парсеры, которые используются для распознавания слов, пробелов, пунктуации и игнорирования ненужных символов. Эти парсеры являются важными для обработки текста и составляют основу для более сложных анализаторов.

\begin{itemize}

\item \textbf{Парсер слов.}  

Этот парсер использует \texttt{some} и \texttt{satisfy}, чтобы считывать последовательность символов, удовлетворяющих предикату \texttt{isWordChar}. Он обрабатывает символы, которые могут быть буквами или апострофами. После того как слово собрано, оно очищается от апострофов с обеих сторон с помощью \texttt{T.dropAround}. Если слово состоит только из апострофов, парсер возвращает \texttt{Nothing}.  

На выходе:  
\begin{itemize}  
    \item Если слово успешно разобрано, парсер возвращает \texttt{Just (remainingText, word)}, где \texttt{remainingText} — остаток строки после обработки, а \texttt{word} — разобранное слово.  
    \item Если слово состоит только из апострофов, парсер возвращает \texttt{Nothing}.  
\end{itemize}  

\item \textbf{Парсер одиночного пробела.}  

Этот парсер использует функцию \texttt{satisfy}, чтобы найти первый символ, который является пробелом. Он использует предикат \texttt{isSpace} для проверки, является ли символ пробелом. Если символ является пробелом, он возвращается как результат парсера.  

На выходе:  
\begin{itemize}  
    \item Если первый символ — пробел, парсер возвращает \texttt{Just (remainingText, ' ')}, где \texttt{remainingText} — остаток строки после обработки, а \texttt{' '} — символ пробела.  
    \item Если первый символ не является пробелом, парсер возвращает \texttt{Nothing}.  
\end{itemize}  

\item \textbf{Парсер последовательности пробелов.}  

Этот парсер использует комбинацию парсеров для обработки одного или нескольких пробелов. Он рекурсивно вызывает \texttt{oneSpace}, чтобы найти первый пробел, а затем повторно использует себя (\texttt{spaces}), чтобы обработать оставшиеся пробелы. Если пробелы закончились, используется \texttt{pure T.empty}, чтобы вернуть пустую строку.  

На выходе:  
\begin{itemize}  
    \item Если строка содержит пробелы, парсер возвращает строку из пробелов, например, \texttt{Just (remainingText, " ")} или \texttt{Just (remainingText, "  ")} в случае нескольких пробелов.  
    \item Если строка не содержит пробелов, парсер возвращает \texttt{Just (remainingText, "")}, то есть пустую строку.  
    \item Если первый символ не является пробелом, парсер возвращает \texttt{Nothing}.  
\end{itemize}  

\item \textbf{Парсер пунктуации.}  

Этот парсер использует \texttt{satisfy}, чтобы найти первый символ, который является одним из символов пунктуации. Для этого используется предикат \texttt{isPunctuation}, который проверяет, является ли символ одним из символов пунктуации, таких как \texttt{'.', '!', '?', ';', ':', '(', ')'}.

На выходе:  
\begin{itemize}  
    \item Если первый символ является символом пунктуации, парсер возвращает \texttt{Just (remainingText, punctuation)}, где \texttt{remainingText} — остаток строки после обработки, а \texttt{punctuation} — сам символ пунктуации.  
    \item Если первый символ не является символом пунктуации, парсер возвращает \texttt{Nothing}.  
\end{itemize}  

\item \textbf{Парсер для пропуска ненужных символов.}  

Этот парсер использует \texttt{T.dropWhile} для пропуска всех символов, которые не являются буквами или символами пунктуации. Он продолжает обработку строки до тех пор, пока не встретит допустимый символ. После этого возвращает остаток строки. Этот парсер полезен для игнорирования символов, которые не имеют значения для анализа (например, пробелы или другие разделители).  

На выходе:  
\begin{itemize}  
    \item Если строка содержит ненужные символы, которые можно пропустить, парсер возвращает остаток строки, начиная с первого допустимого символа. Результат парсинга — \texttt{()}.  
    \item Если строка не содержит допустимых символов, парсер возвращает \texttt{Nothing}.  
\end{itemize}  

\end{itemize}

\subsubsection*{Разбиение текста на предложения}

Данный раздел описывает парсеры, которые анализируют текст, извлекая из него предложения, а затем преобразуют их в различные форматы для дальнейшей обработки.

\begin{itemize}

\item \textbf{Парсер для предложения.}  

Этот парсер разбивает текст на слова и пунктуацию, создавая список слов, которые составляют предложение. Он использует комбинацию парсеров \texttt{word} для получения слов и \texttt{punctuation} для обработки знаков препинания. Для обработки ненужных символов применяется парсер \texttt{skipJunk}.  

Парсер работает следующим образом:  
\begin{itemize}
    \item Сначала он парсит одно или несколько слов, используя парсер \texttt{word}, каждый из которых может быть отделён ненужными символами, которые пропускаются с помощью \texttt{skipJunk}.
    \item Затем он ожидает один или несколько символов пунктуации (например, точку, восклицательный знак, вопросительный знак).
    \item После этого снова пропускаются лишние символы с помощью \texttt{skipJunk}.
    \item Если после этих шагов не осталось текста, возвращается пустой результат (используется \texttt{empty}).
\end{itemize}

На выходе:  
\begin{itemize}
    \item Если предложение успешно разобрано, парсер возвращает \texttt{Just (remainingText, words)}, где \texttt{remainingText} — остаток строки, а \texttt{words} — список слов.
    \item Если не удалось распарсить предложение, возвращается \texttt{Nothing}.
\end{itemize}

\item \textbf{Парсер для всех предложений.}  

Этот парсер использует \texttt{some}, чтобы рекурсивно разобрать несколько предложений с помощью парсера \texttt{sentence}. Он находит все предложения в тексте, разделённые символами, и возвращает их как список предложений.  

На выходе:  
\begin{itemize}
    \item Если предложения успешно разобраны, возвращается список всех предложений: \texttt{Just (remainingText, sentences)}.
    \item Если не удалось распарсить предложения, возвращается \texttt{Nothing}.
\end{itemize}

\item \textbf{Парсер для предложения, представленного как текст.}  

Этот парсер схож с парсером для предложения, но вместо списка слов он возвращает строку, состоящую из слов, соединённых пробелами. Он использует парсер \texttt{joinWords} для объединения списка слов в одну строку. Этот парсер может быть полезен, если нужно собрать предложение в текстовом формате, а не в виде списка отдельных слов.  

На выходе:  
\begin{itemize}
    \item Если предложение успешно разобрано, парсер возвращает строку, представляющую предложение в текстовом виде.
    \item Если не удалось распарсить предложение, возвращается \texttt{Nothing}.
\end{itemize}

\item \textbf{Парсер для всех предложений в текстовом виде.}  

Этот парсер использует \texttt{some}, чтобы разобрать все предложения с помощью парсера \texttt{sentenceAsText}. Он извлекает все предложения, преобразуя каждое в строку, и возвращает их в виде списка текстовых строк.

На выходе:  
\begin{itemize}
    \item Если предложения успешно разобраны, возвращается список строк, представляющих предложения.
    \item Если не удалось распарсить предложения, возвращается \texttt{Nothing}.
\end{itemize}

\end{itemize}

\subsubsection*{Создание N-грамм}

В данном разделе представлен набор функций для генерации N-грамм из списка слов.

\begin{itemize}
    \item \textbf{Тип \texttt{NGramMap}.}  
    Определён тип \texttt{NGramMap} как список пар (\texttt{(Text, [Text])}), где каждый элемент представляет собой пару: слово (или несколько слов) и список слов, которые следуют за ним в тексте. Это основная структура данных для представления N-грамм.

    \item \textbf{Функция \texttt{toBiGrams}.}  
    Эта функция генерирует биграммы (двуграммы) из списка слов. Биграммы — это пары, состоящие из текущего слова и следующего за ним. Функция использует стандартную функцию \texttt{zip} для формирования пар слов: первое слово из списка и следующее за ним.  

    \item \textbf{Функция \texttt{toBiGramsJoined}.}  
    В этой функции генерируются биграммы, где второе слово в паре состоит из двух слов, соединённых пробелом. Для этого используется вспомогательная функция \texttt{triple}, которая разбивает список на тройки подряд идущих слов. После чего слова во второй части тройки объединяются в одну строку с пробелом между ними.  

    \item \textbf{Функция \texttt{triple}.}  
    Эта функция используется для разбиения списка на тройки подряд идущих элементов.

    \item \textbf{Функция \texttt{toTriGrams}.}  
    Генерирует триграммы из списка слов. В отличие от биграмм, триграммы состоят из двух первых слов, соединённых пробелом, и третьего слова, которое следует за ними. Триграммы представляют собой пары: первые два слова объединяются в строку, а третье слово идёт отдельно.

    \item \textbf{Функция \texttt{groupPairs}.}  
    Эта функция принимает список пар и группирует их по первому элементу. Например, если пары содержат одинаковое первое слово, они будут собраны в одну группу, а вторые элементы (слова) будут собраны в список. Это позволяет собрать N-граммы для каждого слова, указывающего на следующие слова или фразы в тексте.

    \item \textbf{Функция \texttt{makeNGrams}.}  
    Функция \texttt{makeNGrams} комбинирует все три предыдущие функции, генерируя полный набор N-грамм из списка слов. Она создаёт:
    \begin{itemize}
        \item Биграммы, где каждое слово сопоставляется с последующим.
        \item Биграммы, где каждое слово сопоставляется с двумя следующими словами, соединёнными пробелом.
        \item Триграммы, где комбинация из двух слов сопоставляется с третьим словом.
    \end{itemize}
    Все эти данные собираются в общий список N-грамм.
\end{itemize}

\subsubsection*{Генерация предложений}

Этот код реализует функционал для обработки текста, создания N-грамм и генерации предложений на основе этих N-грамм.

\begin{itemize}
    \item \textbf{Функция \texttt{processText}.}  
    Эта функция принимает текст и генерирует набор N-грамм для этого текста. В процессе работы:
    \begin{itemize}
        \item Текст парсится с использованием парсера \texttt{allSentences}, который извлекает все предложения.
        \item Все слова из предложений извлекаются и дублируются (с помощью \texttt{nub}, чтобы исключить повторения).
        \item N-граммы генерируются с помощью функции \texttt{makeNGrams}, а дубликаты удаляются.
        \item Добавляются слова, которые не имеют следующих слов в N-граммах. Эти слова добавляются в виде пар с пустыми списками.
        \item Результат сортируется по алфавиту по ключам слов.
    \end{itemize}
    Выходом функции является отсортированный список N-грамм, который затем используется для генерации предложений.

    \item \textbf{Функция \texttt{generatePhrase}.}  
    Эта функция генерирует фразу на основе заданного начального слова и N-грамм, используя генератор случайных чисел. Процесс генерации фразы включает следующие этапы:
    \begin{itemize}
        \item Если первое слово не найдено в словаре N-грамм, возвращается ошибка с сообщением, что слово не найдено.
        \item Если первое слово найдено в словаре, генерируется случайная длина фразы (между 2 и 15 словами).
        \item С помощью рекурсивной функции \texttt{generatePhraseHelper} фраза строится поэтапно, начиная с первого слова и добавляя к фразе подходящие следующие слова.
    \end{itemize}
    На каждом шаге выбирается следующее слово случайным образом из списка возможных слов (на основе текущего слова). Функция рекурсивно добавляет слова в итоговую фразу, пока не будет достигнута заданная длина.

    \item \textbf{Функция \texttt{generatePhraseHelper}.}  
    Эта вспомогательная функция реализует рекурсивную генерацию фразы. Она продолжает добавлять слова в фразу, пока не будет достигнута максимальная длина. Если для текущего слова нет подходящих вариантов продолжения, рекурсия прекращается. Для каждого шага выбирается случайное слово из возможных, добавляется к фразе, и процесс повторяется для нового слова.
    
    \item \textbf{Функция \texttt{findLastValidWord}.}  
    Эта функция ищет первое подходящее слово в фразе, которое встречается в словаре N-грамм. Процесс начинается с последнего слова в фразе и движется к первому. Если слово найдено в словаре, оно возвращается, в противном случае поиск продолжается для предыдущего слова. Если подходящее слово не найдено, возвращается \texttt{Nothing}.
    
    \item \textbf{Типы \texttt{DialogueResponse} и \texttt{DialogueTurn}.}  
    \begin{itemize}
        \item \texttt{DialogueResponse} — это тип, представляющий возможный ответ в диалоге: либо ошибку (\texttt{Left}), либо сгенерированную фразу (\texttt{Right}).
        \item \texttt{DialogueTurn} — это кортеж, состоящий из номера модели и её ответа в виде \texttt{DialogueResponse}.
    \end{itemize}
\end{itemize}

\subsubsection*{Генерация диалога моделей}

Этот код реализует алгоритм для генерации диалога между двумя моделями, которые чередуют свои ответы, используя два набора N-грамм. Алгоритм генерирует последовательность фраз, опираясь на случайные выборы из N-грамм, при этом ограничивает глубину диалога и переключает модели после каждого ответа.

\begin{itemize}
    \item \textbf{Тип \texttt{DialogueResponse}.}  
    Этот тип представляет возможный ответ в диалоге. Он может быть:
    \begin{itemize}
        \item \texttt{Left} — ошибка, если не удалось сгенерировать фразу.
        \item \texttt{Right} — успешный ответ в виде списка слов (фразы).
    \end{itemize}

    \item \textbf{Тип \texttt{DialogueTurn}.}  
    Этот тип представляет один оборот в диалоге, состоящий из:
    \begin{itemize}
        \item Номера модели (1 или 2).
        \item Ответа модели, представленного типом \texttt{DialogueResponse}.
    \end{itemize}

    \item \textbf{Функция \texttt{generateDialogue}.}  
    Основная функция для генерации диалога. Она принимает случайный генератор (\texttt{gen}), начальное слово (\texttt{firstWord}), два набора N-грамм (\texttt{dict1} и \texttt{dict2}), и максимальную глубину диалога (\texttt{depth}).
    \begin{itemize}
        \item Сначала генерируется первый ответ модели 1 с использованием функции \texttt{generatePhrase}.
        \item Затем начинается рекурсивная генерация диалога с помощью вспомогательной функции \texttt{generateDialogueHelper}.
    \end{itemize}
    В результате функция возвращает список диалогов, каждый из которых состоит из номера модели и её ответа.

    \item \textbf{Функция \texttt{generateDialogueHelper}.}  
    Эта функция рекурсивно генерирует последующие фразы диалога.
    \begin{itemize}
        \item Каждый оборот в диалоге начинается с выбора следующей модели (переключение между моделью 1 и моделью 2).
        \item Для каждой модели выбирается соответствующий набор N-грамм.
        \item Для каждого ответа извлекается последнее слово, которое подходит для продолжения диалога (с помощью функции \texttt{findLastValidWord}).
        \item Если подходящее слово найдено, генерируется новый ответ с использованием \texttt{generatePhrase}.
        \item Если слово не найдено, возвращается ошибка с сообщением о невозможности продолжения диалога.
        \item После каждого ответа переключается модель, и процесс повторяется до достижения максимальной глубины диалога (\texttt{depth}).
    \end{itemize}
    Рекурсия завершается, когда глубина диалога достигает нуля.

    \item \textbf{Функция \texttt{findLastValidWord}.}  
    Эта функция ищет последнее подходящее слово из предыдущего ответа, которое существует в словаре N-грамм для следующей модели. Она перебирает слова с конца списка ответа и проверяет их наличие в словаре. Если подходящее слово найдено, оно возвращается, в противном случае возвращается \texttt{Nothing}.
\end{itemize}

\newpage
\section{Результаты}

\subsection{Часть 1. Парсер строк бинарных чисел и операций}

Для проверки работы парсера используется следующий текстовый файл:

\begin{verbatim}
    101010   &   00010   
   1101  |  1011  
  1010 ^ 1001  
1111 & 1100
  10101   |  11011  
   110   ^  100  
   10102 & 00010   
  1101 $  1011 
abcdeftrhg
asd 10101 || 11011 
  10101 || 11011 
 1111 & 1100 extra  
   10101 | 
 |  11011  
 110 ^  ^ 100 
     10101 | 11011   
    101010 & 00010  
  101010 &  00010
  1101    | 1011
 101010&00010 
\end{verbatim}%$

Результаты прохождения тестов, описанных выше, представлены на  Рис. \ref{fig1:1}. 
\begin{center}
	\includegraphics[scale = 1]{1.png}
	\captionof{figure}{Результаты прохождения тестов} 
	\label{fig1:1}
\end{center}

	При запуске программы, пользователь вводит пусть до файла, после чего для каждой строки из файла выводится результат вычисления выражения или сообщение о неверном формате строки.
	
\subsection{Часть 2. Генератор предложений с помощью N-грамм}

Для проверки работы парсера используются текстовые 2 файла содержащих: главы 1 и 2 произведения <<Старуха Изергиль>> на английском языке Максима Горького и стенограмму эпизода 304 <<Твик против Крейга>> мультсериала <<Южный парк>>.

Сначала пользователь вводит начальное слово, с которого будет начинаться предложение первой модели (Рис. \ref{fig2:1}).

\begin{center}
	\includegraphics[scale = 1]{2.png}
	\captionof{figure}{Ввод начального слова} 
	\label{fig2:1}
\end{center}

Затем пользователь вводит глубину сообщений в диалоге (Рис. \ref{}).

\begin{center}
	\includegraphics[scale = 1]{3.png}
	\captionof{figure}{Ввод глубины сообщений диалога} 
	\label{fig2:2}
\end{center}

После этого программа выводит сгенерированный диалог состоящий из реплик двух моделей (Рис. \ref{}).

\begin{center}
	\includegraphics[scale = 1]{4.png}
	\captionof{figure}{Результат работы программы} 
	\label{fig2:3}
\end{center}

По выводу программы видно, что каждая реплика начинается с последнего слова предыдущей реплики или, при отсутствии такого слова в словаре модели, используется предпоследнее слово и так далее.
	
	\newpage

\section*{Заключение}
	\addcontentsline{toc}{section}{Заключение}
	
	\subsection*{Часть 1}

В данной работе был разработан синтаксический анализатор для разбора строк, содержащих битовые выражения с операциями AND, OR и XOR. Анализатор принимает на вход файл формата .txt, содержащий такие выражения, и выводит результаты их вычислений на экран. Реализованный парсер позволяет корректно обрабатывать строки с указанными операциями, обеспечивая удобство использования для конечного пользователя.

\subsection*{Часть 2}

В ходе выполнения данного задания была разработана программа, которая решает задачу синтаксического анализа текста, построения модели N-грамм и генерации фраз на основе этих моделей. В рамках первой части задачи был реализован алгоритм чтения текста из файла, разбивки его на предложения и удаления символов пунктуации и цифр. Во второй части было создано два типа моделей N-грамм: биграммы и триграммы, а также сформирован словарь, который сохранен в файл формата .txt.

Третья часть задачи включала реализацию взаимодействия с пользователем, где пользователь мог вводить одно слово или пару слов, а программа генерировала фразу случайной длины от 2 до 15 слов. Если заданного пользователем слова не находилось среди ключей словаря, выводилось соответствующее сообщение.

Четвертая часть заключалась в организации диалога между двумя моделями N-грамм, созданными на основе различных текстов Максима Горького. Пользователю предоставлялась возможность задать начальное слово или пару слов и указать количество сообщений, которыми будут обмениваться модели. Модели строят свои ответы на основе последнего слова предыдущего сообщения оппонента.

Результаты работы программы демонстрируют корректность алгоритмов обработки текста и построения моделей N-грамм. Полученная система может быть использована для создания простых чат-ботов или других приложений, основанных на анализе естественного языка.

\newpage

\section*{Приложение A. Парсер бинарных операций}
\addcontentsline{toc}{section}{Приложение A. Парсер бинарных операций}
\label{sec:binParser}

\textbf{Lib.hs}

\begin{minted}[
	frame=lines,
	framesep=2mm,
	baselinestretch=1.2,
	bgcolor=LightGray,
	fontsize=\footnotesize,
	linenos,
	breaklines
	]{haskell}
module Lib
    ( parseAndPrint
    , readFileLines
    ) where

import Data.Text (Text)
import qualified Data.Text as T
import qualified Data.ByteString as B
import qualified Data.Text.Encoding as TE
import qualified Data.Text.IO as TIO
import Control.Applicative
import Data.Char (digitToInt, intToDigit)
import Data.Bits ((.&.), (.|.), xor)
import Numeric (showIntAtBase)

newtype Parser a = Parser { runParser :: Text -> Maybe (Text, a) }

instance Functor Parser where
    -- хотим применить func над результатом парсера p
    fmap func (Parser p) = Parser f where
        -- парсер f возвращает:
        f origText = case p origText of
            Nothing -> Nothing -- Nothing, если парсер p возвращает Nothing
            Just (remainingP, resP) -> Just (remainingP, func resP) -- (остаток, resP обработанный функцией func), если p возвращает (остаток, resP)

instance Applicative Parser where
    -- возвращаем всегда (изначальная строка, передаваемое значение)
    pure text = Parser (\orig -> Just(orig, text))

    -- хотим чтобы был парсер, который применяет к остатку 1 парсера 2 парсер,
    -- а затем применяет 1 парсер ко 2
    (Parser u) <*> (Parser v) = Parser f where
        f origText = case u origText of
            Nothing -> Nothing
            -- remainingU - остаток 1 парсера
            Just (remainingU, resU) -> case v remainingU of
                Nothing -> Nothing
                -- remainingV - итоговый остаток, resU применяем над resV
                Just (remainingV, resV) -> Just (remainingV, resU resV)

instance Alternative Parser where
    -- парсер всегда возвращающий Nothing
    empty = Parser $ \_ -> Nothing

    Parser u <|> Parser v = Parser f where
        -- пытаемся применить парсер u
        f origText = case u origText of
            -- если он вернул Nothing, то применям парсер v
            Nothing -> v origText
            -- если вернул какой то результат, то оставляем результат
            res -> res

isBinaryChar :: Char -> Bool
isBinaryChar c =
    c == '0' || c == '1'

isOperation :: Char -> Bool
isOperation c =
    c == '&' || c == '|' || c == '?'

isSpace :: Char -> Bool
isSpace c = c == ' '

satisfy :: (Char -> Bool) -> Parser Char
satisfy pr = Parser f where
    -- берем первый символ
    f cs = case T.uncons cs of
        Nothing -> Nothing
        -- если первый элемент соответствует предикату pr
        Just (fstChar, remainingText)
            | pr fstChar -> Just (remainingText, fstChar) -- то возвращаем (остаток, подоходящий первый элемент)
            | otherwise -> Nothing
    f _ = Nothing

binary :: Parser Text
binary = Parser $ \text ->
    -- если первый элемент
    case runParser (satisfy isBinaryChar) text of
        Nothing -> Nothing -- не подошел, то строка очевидно сразу не подходит
        -- (рекурсивно) если парсер на остатке
        Just (remaining, c) -> case runParser binary remaining of
            Nothing -> Just (remaining, T.singleton c) -- первый элемент не подошел, то берем (старый остаток, единственный подошедший элемент)
            Just (remaining', rest) -> Just (remaining', T.cons c rest) -- сработал штатно, то (новый остаток, добавляем подошедший элемент к остальным)

binToInt :: Text -> Int
binToInt text = T.foldl' (\acc c -> acc * 2 + digitToInt c) 0 text

intToBin :: Int -> Text
intToBin n = T.pack (showIntAtBase 2 intToDigit n "")

binaryInt :: Parser Int
binaryInt = binToInt <$> binary

operation :: Parser Char
operation = satisfy isOperation

oneSpace :: Parser Char
oneSpace = satisfy isSpace

spaces :: Parser Text
spaces = (T.cons) <$> oneSpace <*> spaces <|> pure T.empty

applyOperation :: Char -> Int -> Int -> Int
applyOperation op
    | op == '&' = (.&.)
    | op == '|' = (.|.)
    | op == '?' = xor

binaryExpression :: Parser Int
binaryExpression =
    (\_ b1 _ op _ b2 -> applyOperation op b1 b2)
    <$> spaces
    <*> binaryInt
    <*> spaces
    <*> operation
    <*> spaces
    <*> binaryInt

binaryExpressionFormatted :: Parser Text
binaryExpressionFormatted =
    (\_ b1 _ op _ b2 -> formatExpression b1 op b2)
    <$> spaces
    <*> binary
    <*> spaces
    <*> operation
    <*> spaces
    <*> binary

formatExpression :: Text -> Char -> Text -> Text
formatExpression b1 op b2 =
    let int1 = binToInt b1
        int2 = binToInt b2
        result = applyOperation op int1 int2
    in b1 <> (T.pack " ") <> T.singleton op <> (T.pack " ") <> b2 <> (T.pack " = ") <> intToBin result

readFileLines :: FilePath -> IO [T.Text]
readFileLines filePath = fmap (T.lines . TE.decodeUtf8) (B.readFile filePath)

parseAndPrint :: T.Text -> IO ()
parseAndPrint input = 
    case runParser binaryExpressionFormatted input of
        Just (_, result) -> TIO.putStrLn result
        Nothing -> putStrLn "Wrong string"
\end{minted}
%$

\textbf{Main.hs}
\begin{minted}[
	frame=lines,
	framesep=2mm,
	baselinestretch=1.2,
	bgcolor=LightGray,
	fontsize=\footnotesize,
	linenos,
	breaklines
	]{haskell}
module Main (main) where

import Lib
import System.IO
import qualified Data.Text.Encoding as TE
import qualified Data.ByteString as B

main :: IO ()
main = do
    hSetEncoding stdout utf8
    putStrLn "Enter file name:"
    fileName <- getLine
    lines <- readFileLines fileName
    -- mapM_ (TE.decodeUtf8 . B.putStrLn) lines
    mapM_ parseAndPrint lines
\end{minted}
%$

\newpage

\section*{Приложение Б. Генератор предложений}
\addcontentsline{toc}{section}{Приложение Б. Генератор предложений}
\label{sec:phraseGen}

\textbf{Lib.hs}
\begin{minted}[
	frame=lines,
	framesep=2mm,
	baselinestretch=1.2,
	bgcolor=LightGray,
	fontsize=\footnotesize,
	linenos,
	breaklines
	]{haskell}
module Lib
    ( allSentences
    , runParser
    , generatePhrase
    , processText
    , NGramMap
    , generateDialogue
    ) where

import Control.Applicative
import Data.Text (Text)
import qualified Data.Text as T
import Data.Char (isLetter, isSpace)
import Data.List (sortBy, groupBy, nub)
import System.Random (RandomGen, randomR, next, split)

-- Parser
-- instances

newtype Parser a = Parser { runParser :: Text -> Maybe (Text, a) }

instance Functor Parser where
    -- хотим применить func над результатом парсера p
    fmap func (Parser p) = Parser f where
        -- парсер f возвращает:
        f origText = case p origText of
            Nothing -> Nothing -- Nothing, если парсер p возвращает Nothing
            Just (remainingP, resP) -> Just (remainingP, func resP) -- (остаток, resP обработанный функцией func), если p возвращает (остаток, resP)

instance Applicative Parser where
    -- возвращаем всегда (изначальная строка, передаваемое значение)
    pure text = Parser (\orig -> Just(orig, text))

    -- хотим чтобы был парсер, который применяет к остатку 1 парсера 2 парсер,
    -- а затем применяет 1 парсер ко 2
    (Parser u) <*> (Parser v) = Parser f where
        f origText = case u origText of
            Nothing -> Nothing
            -- remainingU - остаток 1 парсера
            Just (remainingU, resU) -> case v remainingU of
                Nothing -> Nothing
                -- remainingV - итоговый остаток, resU применяем над resV
                Just (remainingV, resV) -> Just (remainingV, resU resV)

instance Alternative Parser where
    -- парсер всегда возвращающий Nothing
    empty = Parser $ \_ -> Nothing

    Parser u <|> Parser v = Parser f where
        -- пытаемся применить парсер u
        f origText = case u origText of
            -- если он вернул Nothing, то применям парсер v
            Nothing -> v origText
            -- если вернул какой то результат, то оставляем результат
            res -> res

-- functions

isPunctuation :: Char -> Bool
isPunctuation c = c `elem` ['.', '!', '?', ';', ':', '(', ')']

joinWords :: [Text] -> Text
joinWords = T.intercalate (T.pack " ")

-- parsers

satisfy :: (Char -> Bool) -> Parser Char
satisfy pr = Parser f where
    -- берем первый символ
    f cs = case T.uncons cs of
        Nothing -> Nothing
        -- если первый элемент соответствует предикату pr
        Just (fstChar, remainingText)
            | pr fstChar -> Just (remainingText, fstChar) -- то возвращаем (остаток, подоходящий первый элемент)
            | otherwise -> Nothing
    f _ = Nothing

isWordChar :: Char -> Bool
isWordChar c = isLetter c || c == '\''

word :: Parser Text
word = Parser f where
    f input = case runParser (some (satisfy isWordChar)) input of
        Nothing -> Nothing
        Just (remaining, chars) -> 
            -- проверяем что слово начинается или заканчивается апострофом
            let word = T.pack chars
                cleanWord = T.dropAround (== '\'') word
            in if T.null cleanWord 
                then Nothing  -- если слово состоит только из апострофов, то возвращаем Nothing
                else Just (remaining, word)

oneSpace :: Parser Char
oneSpace = satisfy isSpace

spaces :: Parser Text
spaces = (T.cons) <$> oneSpace <*> spaces <|> pure T.empty

punctuation :: Parser Char
punctuation = satisfy isPunctuation

skipJunk :: Parser ()
skipJunk = Parser f where
    f input = Just (T.dropWhile (\c -> not (isLetter c || isPunctuation c)) input, ())

sentence :: Parser [Text]
sentence = (\words _ -> words) 
    <$> some (word <* skipJunk)
    <*> some punctuation
    <* skipJunk
    <|> empty

allSentences :: Parser [[Text]]
allSentences = some sentence

sentenceAsText :: Parser Text
sentenceAsText = (\words _ -> joinWords words)
    <$> some (word <* skipJunk)
    <*> some punctuation
    <* skipJunk
    <|> empty

allSentencesAsText :: Parser [Text]
allSentencesAsText = some sentenceAsText

-- N-gram

type NGramMap = [(Text, [Text])]

toBiGrams :: [Text] -> [(Text, Text)]
toBiGrams words = zip words (tail words)

toBiGramsJoined :: [Text] -> [(Text, Text)]
toBiGramsJoined ws = 
    [(w1, T.concat [w2, T.pack " ", w3]) | (w1,w2,w3) <- triple ws]

triple :: [a] -> [(a, a, a)]
triple (x:y:z:rest) = (x,y,z) : triple (y:z:rest)
triple _ = []

toTriGrams :: [Text] -> [(Text, Text)]
toTriGrams ws = 
    [(T.concat [w1, T.pack " ", w2], w3) | (w1,w2,w3) <- triple ws]


groupPairs :: [(Text, Text)] -> NGramMap
groupPairs pairs = map (\group -> (fst $ head group, map snd group)) 
                  $ groupBy (\x y -> fst x == fst y) 
                  $ sortBy (\x y -> compare (fst x) (fst y)) pairs

makeNGrams :: [Text] -> [(Text, Text)]
makeNGrams words = 
    -- создаем биграммы вида (word -> next word)
    toBiGrams words ++
    -- создаем биграммы вида (word -> two next words joined)
    toBiGramsJoined words ++
    -- создаем триграммы вида (two words -> next word)
    toTriGrams words

processText :: Text -> NGramMap
processText text = case runParser allSentences text of
    Nothing -> []
    Just (_, sentences) -> let
        -- берем все слова из всех предложений
        allWords = nub $ concat sentences
        -- создаем n-граммы из всех предложений и удаляем дубликаты
        allNGrams = groupPairs 
                   $ nub -- удаляем дубликаты
                   $ concatMap makeNGrams sentences
        -- добавляем слова, которые не имеют следующих слов
        singleWords = map (\w -> (w, [])) 
                     $ filter (\w -> not $ any (\(prefix, _) -> prefix == w) allNGrams) 
                     $ allWords
        in sortBy (\x y -> compare (fst x) (fst y)) 
           $ allNGrams ++ singleWords

generatePhrase :: RandomGen g => g -> Text -> NGramMap -> Either Text [Text]
generatePhrase gen firstWord nGrams = 
    -- если первого слова нет в словаре, то возвращаем ошибку (Left ошибка, Right [слова для фразы])
    case lookup firstWord nGrams of
        Nothing -> Left $ T.concat [T.pack "Word '", firstWord, T.pack "' not found in the dictionary"]
        -- если первое слово есть в словаре, то начинаем генерировать фразу
        Just nextWords -> 
            let (targetLength, newGen) = randomR (2, 15) gen
            in Right $ generatePhraseHelper newGen [firstWord] firstWord nGrams targetLength

generatePhraseHelper :: RandomGen g => g -> [Text] -> Text -> NGramMap -> Int -> [Text]
generatePhraseHelper gen acc lastKey nGrams targetLength
    | length acc >= targetLength = take targetLength acc  -- достигли максимальной длины
    | null possibleNextWords = acc  -- нет больше слов
    | otherwise = 
        let (idx, newGen) = randomR (0, length possibleNextWords - 1) gen
            nextWord = possibleNextWords !! idx
            -- если два слова, то разбиваем на два
            nextWords = T.words nextWord
            -- и добавляем в список слов фразы
            newAcc = acc ++ nextWords
            -- используем следующее слово (или два слова) как ключ для следующего шага
            newKey = nextWord
        -- рекурсивно вызываем функцию для следующего шага
        in generatePhraseHelper newGen newAcc newKey nGrams targetLength
  where
    -- находим список слов по данному ключу (Just [Text]), если такого ключа в словаре нет, то Nothing
    possibleNextWords = maybe [] id $ lookup lastKey nGrams

-- Найти первое подходящее слово от конца фразы, которое есть в словаре
findLastValidWord :: [Text] -> NGramMap -> Maybe Text
findLastValidWord [] _ = Nothing
findLastValidWord (word:rest) nGrams = 
    case lookup word nGrams of
        Just _ -> Just word
        Nothing -> findLastValidWord rest nGrams

type DialogueResponse = Either Text [Text]  -- Left - ошибка, Right - фраза
type DialogueTurn = (Int, DialogueResponse)  -- (номер модели, ответ)

generateDialogue :: RandomGen g => 
                   g ->           
                   Text ->        
                   NGramMap ->    
                   NGramMap ->    
                   Int ->         
                   [DialogueTurn]  -- возвращает список (номер модели, ответ)
generateDialogue gen firstWord dict1 dict2 depth = 
    let firstResponse = generatePhrase gen firstWord dict1
        (_, newGen) = next gen
    in (1, firstResponse) : generateDialogueHelper newGen firstResponse 1 dict1 dict2 depth []

generateDialogueHelper :: RandomGen g => 
                         g -> 
                         DialogueResponse -> -- последний ответ
                         Int ->              -- номер модели
                         NGramMap ->         -- первый словарь
                         NGramMap ->         -- второй словарь
                         Int ->              -- остаток глубины
                         [DialogueTurn] ->   -- накопленный диалог
                         [DialogueTurn]      -- финальный диалог
generateDialogueHelper _ _ _ _ _ 0 acc = reverse acc
generateDialogueHelper gen lastResponse speaker dict1 dict2 depth acc =
    let 
        -- следующая модель
        nextSpeaker = if speaker == 1 then 2 else 1
        
        -- словарь для следующей модели
        currentDict = if nextSpeaker == 1 then dict1 else dict2
        
        -- последнее подходящее слово из предыдущего ответа
        lastWords = case lastResponse of
            Right phrase -> reverse phrase  -- если слово есть
            Left _ -> []                   -- если нет, то пустой список
        
        -- последнее подходящее слово из предыдущего ответа
        nextWord = findLastValidWord lastWords currentDict
        
        -- следующий ответ (даже если не нашли подходящего слова)
        nextResponse = case nextWord of
            Nothing -> Left (T.pack "No valid word found to continue dialogue")
            Just word -> 
                let (newGen1, _) = split gen
                in generatePhrase newGen1 word currentDict
        
        (_, newGen2) = split gen
    in generateDialogueHelper 
        newGen2 
        nextResponse
        nextSpeaker 
        dict1 
        dict2 
        (depth - 1) 
        ((nextSpeaker, nextResponse) : acc)
\end{minted}

\textbf{Main.hs}
\begin{minted}[
	frame=lines,
	framesep=2mm,
	baselinestretch=1.2,
	bgcolor=LightGray,
	fontsize=\footnotesize,
	linenos,
	breaklines
	]{haskell}
module Main (main) where

import Lib
import qualified Data.Text as T
import qualified Data.Text.IO as TIO
import System.Random (newStdGen)

main :: IO ()
main = do

    input1 <- TIO.readFile "input.txt"
    input2 <- TIO.readFile "input2.txt"
    
    let nGrams1 = processText input1
    let nGrams2 = processText input2

    -- print nGrams1
    -- print "\n"
    -- print nGrams2
    -- print "\n"
    
    TIO.putStrLn (T.pack "Enter the first word for dialogue:")
    firstWord <- T.strip <$> TIO.getLine
    
    TIO.putStrLn (T.pack "Enter the number of exchanges:")
    depthStr <- getLine
    let depth = (read depthStr :: Int) - 1
    
    gen <- newStdGen
    let dialogue = generateDialogue gen firstWord nGrams1 nGrams2 depth
    TIO.putStrLn (T.pack "\nGenerated dialogue:")
    mapM_ (printDialogueTurn . formatDialogueTurn) dialogue
  where
    formatDialogueTurn (speaker, response) = 
        (T.pack $ "Model " ++ show speaker ++ ": ", 
         case response of
            Left err -> err
            Right phrase -> T.unwords phrase)
    
    printDialogueTurn (prefix, message) = 
        TIO.putStr prefix >> TIO.putStrLn message
\end{minted}

\end{document}
